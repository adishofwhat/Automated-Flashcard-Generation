{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing"
      ],
      "metadata": {
        "id": "cw5jHYo5fhqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgbQXH9h-MBa",
        "outputId": "2f8f478d-ee27-4faf-9ccb-2abffab798d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=13c3c704b850a4dd6f0d32aa9eecaea612823d62c742a103d710afa47608134e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZtkL_BvB4Cg",
        "outputId": "4d4223a4-52ba-4f2f-fc72-1be3a1dbd913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.46.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.26.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwhepGNE-g_Y",
        "outputId": "6b473a57-b089-481f-8255-a74f3feacb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Collecting peft\n",
            "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.6)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.8.30)\n",
            "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.13.2\n",
            "    Uninstalling peft-0.13.2:\n",
            "      Successfully uninstalled peft-0.13.2\n",
            "Successfully installed peft-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLa_qby69r-Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5Config\n",
        "from safetensors.torch import load_file\n",
        "import json\n",
        "import os\n",
        "from peft import PeftModel, PeftConfig\n",
        "import nltk\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import logging\n",
        "\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "B38hHcrobC-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wsCIVUPaamJ",
        "outputId": "0a602468-3623-43eb-efc9-e3b60556ad1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Assessment"
      ],
      "metadata": {
        "id": "3-QTfOcsfnHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_qa(context, model, tokenizer):\n",
        "    print(\"Context: \")\n",
        "    print(context)\n",
        "    inputs = tokenizer(context, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_length=500, num_return_sequences=1, num_beams=4)\n",
        "    question_answer = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "    print(\"Generated QA: \")\n",
        "    print(question_answer)\n",
        "    print(\"-\" * 50)\n",
        "    question_answer = question_answer.replace(tokenizer.pad_token, \"\").replace(tokenizer.eos_token, \"\")\n",
        "\n",
        "    if tokenizer.sep_token in question_answer:\n",
        "        question, answer = question_answer.split(tokenizer.sep_token, 1)\n",
        "        generated_qa = f\"{question} {answer}\"\n",
        "    else:\n",
        "        generated_qa = question_answer\n",
        "\n",
        "    return generated_qa\n",
        "\n",
        "def compute_rouge_l(reference, candidate):\n",
        "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "    rouge_result = scorer.score(reference, candidate)\n",
        "    precision = rouge_result['rougeL'].precision\n",
        "    recall = rouge_result['rougeL'].recall\n",
        "    f1_score = rouge_result['rougeL'].fmeasure\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "def compute_bert_score(reference, candidate):\n",
        "    precision, recall, f1 = score([candidate], [reference], lang=\"en\", verbose=False)\n",
        "    return precision.mean().item(), recall.mean().item(), f1.mean().item()\n",
        "\n",
        "\n",
        "def evaluate_context_matching(contexts, model, tokenizer):\n",
        "    rouge_metrics = {'precision': [], 'recall': [], 'f1': []}\n",
        "    bert_metrics = {'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "    for context in contexts:\n",
        "        generated_qa = generate_qa(context, model, tokenizer)\n",
        "\n",
        "        rouge_precision, rouge_recall, rouge_f1 = compute_rouge_l(context, generated_qa)\n",
        "        rouge_metrics['precision'].append(rouge_precision)\n",
        "        rouge_metrics['recall'].append(rouge_recall)\n",
        "        rouge_metrics['f1'].append(rouge_f1)\n",
        "\n",
        "        bert_precision, bert_recall, bert_f1 = compute_bert_score(context, generated_qa)\n",
        "        bert_metrics['precision'].append(bert_precision)\n",
        "        bert_metrics['recall'].append(bert_recall)\n",
        "        bert_metrics['f1'].append(bert_f1)\n",
        "\n",
        "    summary = {\n",
        "        'metrics': {metric: np.mean(values) for metric, values in bert_metrics.items()}\n",
        "    }\n",
        "\n",
        "    return summary\n",
        "\n",
        "def preprocess_function_with_nltk(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    pos_str = \" \".join([f\"{word}/{pos}\" for word, pos in pos_tags])\n",
        "\n",
        "    ner_tree = nltk.ne_chunk(pos_tags)\n",
        "    ner_tags = \" \".join([f\"{' '.join(c[0] for c in subtree)}({subtree.label()})\" if isinstance(subtree, nltk.Tree) else f\"{subtree[0]}\" for subtree in ner_tree])\n",
        "\n",
        "    return ner_tags, pos_str"
      ],
      "metadata": {
        "id": "VMSg_lb7Flsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset using pandas\n",
        "splits = {\n",
        "    'train': 'data/train-00000-of-00001.parquet',\n",
        "    'validation': 'data/validation-00000-of-00001.parquet',\n",
        "    'test': 'data/test-00000-of-00001.parquet'\n",
        "}\n",
        "train_df = pd.read_parquet(\"hf://datasets/allenai/sciq/\" + splits[\"train\"])\n",
        "validation_df = pd.read_parquet(\n",
        "    \"hf://datasets/allenai/sciq/\" + splits[\"validation\"])\n",
        "test_df = pd.read_parquet(\"hf://datasets/allenai/sciq/\" + splits[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv1E9cFCpz_4",
        "outputId": "b4d44bfe-6753-4e57-bd1f-f60c393f0af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts = test_df[\"support\"]\n",
        "\n",
        "contexts.replace('', np.nan, inplace=True)\n",
        "contexts.dropna(how='all', inplace=True)\n",
        "\n",
        "contexts = list(contexts)\n",
        "\n",
        "contexts = contexts[:10]\n",
        "\n",
        "print(len(contexts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOGYnP0hP4iY",
        "outputId": "4a0ebe2f-6c53-48f2-c2e5-4ac49af0b902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# contexts"
      ],
      "metadata": {
        "id": "j9u-i1mZXUHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_tag(contexts):\n",
        "    finetuned_model_dir = \"/content/finetuned_squad\"\n",
        "\n",
        "    finetuned_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_dir)\n",
        "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(finetuned_model_dir)\n",
        "\n",
        "    finetuned_model = PeftModel.from_pretrained(finetuned_model, finetuned_model_dir)\n",
        "\n",
        "    tagged_contexts_ner = []\n",
        "    tagged_contexts_pos = []\n",
        "    for context in contexts:\n",
        "        ner_tags, pos_tags = preprocess_function_with_nltk(context)\n",
        "        tagged_contexts_ner.append(ner_tags)\n",
        "        tagged_contexts_pos.append(pos_tags)\n",
        "\n",
        "    finetuned_metrics = evaluate_context_matching(contexts, finetuned_model, finetuned_tokenizer)\n",
        "\n",
        "    print(\"Fine-tuned Model Metrics:\", finetuned_metrics)"
      ],
      "metadata": {
        "id": "k1sAu7YQQhCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model_tag(contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZB2Sdb5RaPI",
        "outputId": "f57987f7-0067-4fd9-dd41-12079e3b8ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: \n",
            "Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\n",
            "Generated QA: \n",
            "<pad> Compounds that are capable of accepting electrons, such as o 2 or f2, are called what?<sep> oxidants</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "But transgenic animals just have one novel gene. What about an animal with a whole new genome? Could a clone , a genetically exact copy of an organism, be developed using techniques associated with biotechnology? It could be argued that human cloning is one of the inevitable outcomes of modern biotechnology. It \"simply\" involves the removal of the nucleus from a somatic cell and its placement into an unfertilized egg cell whose nucleus has either been deactivated or removed. This new cell would mimic the zygote, the first diploid cell of a new organism. This new zygote is allowed to become established, and a few days later is placed into the uterus of a surrogate mother. Theoretically this would result in an individual genetically identical to the donor. Obviously, there are many ethical and legal issues associated with human cloning, and of course, it is not a \"simple\" procedure. But animal cloning is arguably a different story.\n",
            "Generated QA: \n",
            "<pad> What is the term for a genetically exact copy of an organism?<sep> clone</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "Figure 29.7 Vertebrata are characterized by the presence of a backbone, such as the one that runs through the middle of this fish. All vertebrates are in the Craniata clade and have a cranium. (credit: Ernest V. More; taken at Smithsonian Museum of Natural History, Washington, D.\n",
            "Generated QA: \n",
            "<pad> All vertebrates are in the craniata clade and have what?<sep> cranium</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "As you know, the surface of Earth is not flat. Some places are high, and some places are low. For example, mountain ranges like the Sierra Nevada in California or the Andes in South America are high above the surrounding areas. An accurate location must take into account the third dimension. Elevation is the height above or below sea level. Sea level refers to the height of the ocean’s surface. This is the midpoint between high and low tide. Sea level can vary from place to place, but scientists base their elevation measurements on the average, or mean, sea level to make sure they have a standard reference point.\n",
            "Generated QA: \n",
            "<pad> What is the term for the height above or below sea level?<sep> elevation</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "Tree rings, ice cores, and varves indicate the environmental conditions at the time they were made.\n",
            "Generated QA: \n",
            "<pad> Tree rings, ice cores, and varves indicate what at the time they were made?<sep> environmental conditions</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "Plant hormones are chemical signals that control different processes in plants.\n",
            "Generated QA: \n",
            "<pad> What are chemical signals that control different processes in plants?<sep> plant hormones</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "Gametogenesis (Spermatogenesis and Oogenesis) Gametogenesis, the production of sperm and eggs, involves the process of meiosis. During meiosis, two nuclear divisions separate the paired chromosomes in the nucleus and then separate the chromatids that were made during an earlier stage of the cell’s life cycle. Meiosis and its associated cell divisions produces haploid cells with half of each pair of chromosomes normally found in diploid cells. The production of sperm is called spermatogenesis and the production of eggs is called oogenesis. Spermatogenesis Spermatogenesis occurs in the wall of the seminiferous tubules, with the most primitive cells at the periphery of the tube and the most mature sperm at the lumen of the tube (Figure 18.14). Immediately under the capsule of the tubule are diploid, undifferentiated cells. These stem cells, each called a spermatogonium (pl. spermatogonia), go through mitosis to produce one cell that remains as a stem cell and a second cell called a primary spermatocyte that will undergo meiosis to produce sperm. The diploid primary spermatocyte goes through meiosis I to produce two haploid cells called secondary spermatocytes. Each secondary spermatocyte divides after meiosis II to produce two cells called spermatids. The spermatids eventually reach the lumen of the tubule and grow a flagellum, becoming sperm cells. Four sperm result from each primary spermatocyte that goes through meiosis.\n",
            "Generated QA: \n",
            "<pad> Gametogenesis, the production of sperm and eggs, involves the process of what?<sep> meiosis</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "Figure 44.18 Deciduous trees are the dominant plant in the temperate forest. (credit: Oliver Herold).\n",
            "Generated QA: \n",
            "<pad> What is the dominant plant in the temperate forest?<sep> deciduous trees</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "There is also a correlation between viscosity and molecular shape. Liquids consisting of long, flexible molecules tend to have higher viscosities than those composed of more spherical or shorter-chain molecules. The longer the molecules, the easier it is for them to become “tangled” with one another, making it more difficult for them to move past one another. London dispersion forces also increase with chain length. Due to a combination of these two effects, long-chain hydrocarbons (such as motor oils) are highly viscous.\n",
            "Generated QA: \n",
            "<pad> Liquids consisting of long, flexible molecules tend to have higher what than those composed of more spherical or shorter-chain molecules?<sep> viscosity</s>\n",
            "--------------------------------------------------\n",
            "Context: \n",
            "Ionic compounds have strong electrostatic attractions between oppositely charged ions in a regular array. The lattice energy (U) of an ionic substance is defined as the energy required to dissociate the solid into gaseous ions; U can be calculated from the charges on the ions, the arrangement of the ions in the solid, and the internuclear distance. Because U depends on the product of the ionic charges, substances with dior tripositive cations and/or di- or trinegative anions tend to have higher lattice energies than their singly charged counterparts. Higher lattice energies typically result in higher melting points and increased hardnessbecause more thermal energy is needed to overcome the forces that hold the ions together. Lattice energies cannot be measured directly but are obtained from a thermochemical cycle called the Born–Haber cycle, in which Hess’s law is used to calculate the lattice energy from the measured enthalpy of formation of the ionic compound, along with other thermochemical data. The Born–Haber cycle can be used to predict which ionic compounds are likely to form. Sublimation, the conversion of a solid directly to a gas, has an accompanying enthalpy change called the enthalpy of sublimation.\n",
            "Generated QA: \n",
            "<pad> Ionic compounds have strong electrostatic attractions between oppositely charged ions in a regular array. the lattice energy (u) of an ionic substance is defined as the energy required to dissociate the solid into what?<sep> gaseous ions</s>\n",
            "--------------------------------------------------\n",
            "Fine-tuned Model Metrics: {'bert_metrics': {'precision': 0.9078778445720672, 'recall': 0.8525043427944183, 'f1': 0.8787162780761719}}\n"
          ]
        }
      ]
    }
  ]
}